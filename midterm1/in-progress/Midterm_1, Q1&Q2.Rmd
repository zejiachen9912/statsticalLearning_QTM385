---
title: "Q1 & Q2"
author: "Zejia Chen"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  prettydoc::html_pretty:
    df_print: kable
    theme: material
    highlight: github
    toc: no
    toc_depth: 2
    toc_float:
      collapsed: no
urlcolor: blue
---

```{r, include=FALSE}
library(ggplot2)
library(data.table)
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, fig.width = 16/2, fig.height = 9/2, tidy.opts=list(width.cutoff=60), tidy=TRUE)
```


# Problem 1
```{r}
rm(list=ls(all=TRUE))
setwd("/Users/zejiachen/Desktop/Sspring 2022/Statstical Learning/midterm1")
df_train <- read.csv("midterm1_train.csv")
df_test <- read.csv("midterm1_testProto.csv")
```

Data Cleaning
```{r}
# take of log of `share`
df_train$shares = log(df_train$shares)
df_test$shares = log(df_test$shares)
```

```{r}
# adding the `viral content category` variable

df_train$data_channel_is_viral = df_train$data_channel_is_lifestyle

for (i in 1:nrow(df_train)){
  if (df_train[i, "data_channel_is_lifestyle"] == 0 &
      df_train[i, "data_channel_is_entertainment"] == 0 &
      df_train[i, "data_channel_is_bus"] == 0 &
      df_train[i, "data_channel_is_socmed"] == 0 &
      df_train[i, "data_channel_is_tech"] == 0 &
      df_train[i, "data_channel_is_world"] == 0){
    
        df_train[i, "data_channel_is_viral"] = 1
        
  } else{
        df_train[i, "data_channel_is_viral"] = 0
      }
}

df_train$data_channel_is_viral <- as.integer(df_train$data_channel_is_viral)

```

```{r}
df_test$data_channel_is_viral = df_test$data_channel_is_lifestyle

for (i in 1:nrow(df_test)){
  if (df_test[i, "data_channel_is_lifestyle"] == 0 &
      df_test[i, "data_channel_is_entertainment"] == 0 &
      df_test[i, "data_channel_is_bus"] == 0 &
      df_test[i, "data_channel_is_socmed"] == 0 &
      df_test[i, "data_channel_is_tech"] == 0 &
      df_test[i, "data_channel_is_world"] == 0){
    
        df_test[i, "data_channel_is_viral"] = 1
        
  } else{
        df_test[i, "data_channel_is_viral"] = 0
      }
}

df_test$data_channel_is_viral <- as.integer(df_test$data_channel_is_viral)
```


```{r}
# dropping variables that might cause collinearity issue

df_train <- subset(df_train, select = -c(is_weekend, LDA_04, url))

df_test <- subset(df_test, select = -c(is_weekend, LDA_04, url))

```

---
## Model Testing
```{r}
library(caret)
library(glmnet)
library(dplyr)
```


**Multiple Linear Regression**

`Coefficients: (2 not defined because of singularities)` ??

```{r}
lm_fit <- lm(shares ~ ., data = df_train)

LOOCV <- mean((lm_fit$residuals/(1-hatvalues(lm_fit)))^2)

print(paste("LOOCV: ", round(LOOCV, 5)))
print(paste("sqrt(LOOCV): ", round(sqrt(LOOCV), 5)))

```


```{r}
coef_df <- data.frame(lm_fit$coefficients)
colnames(coef_df)[1] <- "coef"
coef_df$coef <- round(coef_df$coef, 3)

coef_df %>% arrange(desc(coef)) %>%top_n(12)
```


**KNN**

Error: `#Error: vector memory exhausted (limit reached?)`

Subset data
```{r}
set.seed(1234)

ind <- sample(2, nrow(df_train), replace = T, prob = c(0.5, 0.5))
df_train_sample <- df_train[ind == 1, ]
```

```{r}
trControl <- trainControl(method = "cv", number = 10)
 
set.seed(1234)
 
knn_fit <- train(shares ~., data = df_train_sample, method = 'knn',
              trControl = trControl)
```

```{r}
knn_fit

plot(knn_fit)

print(paste("RMSE: ", 0.9322533))

```

```{r}
varImp <- varImp(knn_fit)

varImp <- data.frame(varImp[1])

varImp %>% arrange(desc(varImp)) %>%top_n(12)
```


**LASSO**
```{r}
trn_x <- as.matrix(df_train[,-58])
trn_y <- as.matrix(df_train$shares)
```


```{r}
fit_cv_LASSO<- cv.glmnet(trn_x, trn_y, type.measure = "mse", alpha = 1, family = "gaussian", nfolds = 10)

plot(fit_cv_LASSO)
```

```{r}
fit_cv_LASSO

print(paste("RMSE: ", round(sqrt(0.7711), 5)))
```

Let use `1se` to retrieve our ‘significant’ predictors, since it minimize the number of predictor. Since there 50+ predictors, we might want to eliminate as much predictors as possible, preventing any cases of overfitting so that we can reduce as much variance during the validation process. 
```{r}

coef_optim_LASSO <- coef(fit_cv_LASSO, s= fit_cv_LASSO$lambda.1se)

```

```{r}
theme_set(theme_bw())
coef_df <- as.data.frame(summary(coef_optim_LASSO))
col_names_df <- rbind(c("Intercept", 0),data.frame(colnames(trn_x)))
# saving all leftover significant predictors
coef_shrink <- col_names_df[c(coef_df$i),1]
coef_df <- cbind(coef_shrink, coef_df)
coef_df <- coef_df[,-c(2,3)]
colnames(coef_df)[1] <- "predictors"
colnames(coef_df)[2] <- "coef"
coef_df$coef <- round(coef_df$coef, 7)

coef_df %>% arrange(desc(coef)) %>% top_n(12)
coef_df %>% arrange(desc(coef)) %>% top_n(-10)

```

**GAM**
```{r}
library(mgcv)
```

We will just use the top five most positive & negative predictors selected by LASSO.

```{r}
gam1<-gam(shares~ global_subjectivity + weekday_is_saturday + weekday_is_sunday
          + data_channel_is_socmed + s(LDA_00) + data_channel_is_tech + s(abs_title_subjectivity)
          + s(global_rate_positive_words) 
          + s(min_positive_polarity) + s(LDA_02) + data_channel_is_bus	+ s(LDA_03)
          + data_channel_is_entertainment + s(LDA_01), data=df_train)

plot(gam1, pages = 1)
```

```{r}
round(sqrt(summary(gam1)$sp.criterion), 5)
```

**Random Forest**
```{r}
library(ranger)
```

```{r}
set.seed(1234)

rf_fit <- ranger(shares ~ ., data = df_train, mtry = floor(sqrt(ncol(df_train) - 1)), num.trees = 1000)
```

```{r}
rf_fit
```

Variable Importance
```{r}
rf_fit2 <- ranger(shares ~ ., data = df_train, mtry = floor(sqrt(ncol(df_train) - 1)), 
                  num.trees = 1000, importance = 'permutation')
rf_fit3 <- ranger(shares ~ ., data = df_train, mtry = floor(sqrt(ncol(df_train) - 1)), 
                  num.trees = 1000, importance = 'impurity')
```

```{r}
colnames <- colnames(df_train)
colnames <- colnames[-58]

rf_fit2_varImp <- data.frame(rf_fit2$variable.importance)
rf_fit2_varImp$Predictors <- colnames
colnames(rf_fit2_varImp)[1] <- "Importance"
rf_fit2_top <- rf_fit2_varImp %>% arrange(desc(rf_fit2_varImp))
rf_fit2_top <- rf_fit2_top[1:15,]


rf_fit3_varImp <- data.frame(rf_fit3$variable.importance)
rf_fit3_varImp$Predictors <- colnames
colnames(rf_fit3_varImp)[1] <- "Importance"
rf_fit3_top <- rf_fit3_varImp %>% arrange(desc(rf_fit3_varImp))
rf_fit3_top <- rf_fit3_top[1:15,]
```

```{r}
fit1 <- ggplot(rf_fit2_top, aes(x=reorder(Predictors,-Importance), y=Importance, label=round(Importance, 3))) + 
  geom_point(col="tomato2", size=3) +   # Draw points
  geom_segment(aes(x=Predictors, 
                   xend=Predictors, 
                   y=min(Importance), 
                   yend=max(Importance)), 
               linetype="dashed", 
               size=0.1) +   # Draw dashed lines
  labs(title="Variable Importance", y = "Importance", x = "Predictors") +  
  coord_flip()
```

```{r}
fit2 <- ggplot(rf_fit3_top, aes(x=reorder(Predictors,-Importance), y=Importance, label=round(Importance, 3))) + 
  geom_point(col="tomato2", size=3) +   # Draw points
  geom_segment(aes(x=Predictors, 
                   xend=Predictors, 
                   y=min(Importance), 
                   yend=max(Importance)), 
               linetype="dashed", 
               size=0.1) +   # Draw dashed lines
  labs(title="Variable Importance", y = "Importance", x = "Predictors") +  
  coord_flip()
```


```{r}
library("ggpubr")
ggarrange(fit1, fit2,
          labels = c("Permutation", "Impurity"))
```

**Boosted Regression Tree**
```{r}
library(gbm)
```

```{r}
set.seed(1234)

boost_tree_1 <- gbm(shares ~., data = df_train, distribution = "gaussian", 
                    n.trees = 1000, interaction.depth = 1, shrinkage = 0.005, bag.fraction = 1, cv.folds = 5)

boost_tree_2 <- gbm(shares ~., data = df_train, distribution = "gaussian", 
                    n.trees = 1000, interaction.depth = 2, shrinkage = 0.005, bag.fraction = 1, cv.folds = 5)
```

```{r}
# importance measure
df <- data.frame(summary(boost_tree_1, plotit = FALSE))
df %>% arrange(desc(df$rel.inf)) %>% top_n(10)

df <- data.frame(summary(boost_tree_2, plotit = FALSE))
df %>% arrange(desc(df$rel.inf)) %>% top_n(10)


# CV estimate of EPE at each step
plot(seq(1, 1000), boost_tree_1$cv.error, type = "l")
plot(seq(1, 1000), boost_tree_2$cv.error, type = "l")
```

```{r}
print(paste("boost_tree_1: ", boost_tree_1$cv.error[1000]))
print(paste("boost_tree_2: ", boost_tree_2$cv.error[1000]))

```


## Comparison between different models

```{r}
# linear
round(sqrt(LOOCV), 5)

# knn
print(0.9322533)

# LASSO
round(sqrt(0.7711), 5)

# GAM
round(sqrt(summary(gam1)$sp.criterion), 5)

# RF
round(sqrt(0.720559), 5)

# BRF
round(sqrt(boost_tree_2$cv.error[1000]), 5)

```

```{r}
RMSE <- c(round(sqrt(LOOCV), 5), 0.93225, round(sqrt(0.7711), 5), 0.89211, 
          round(sqrt(0.720559), 5),
          round(sqrt(boost_tree_2$cv.error[1000]), 5))

Model <- c('Linear', 'KNN', 'LASSO', 'GAM', 'Random Forest', 'Boosted Random Forest')
```

```{r}
model_compare <- data.frame(Model, RMSE)
model_compare %>% arrange(model_compare$RMSE) %>% top_n(10)
```

## Validation

```{r}
tst_x <- as.matrix(df_test[,-58])
tst_y <- as.matrix(df_test$shares)
```


---
# Problem 2

...


---
# Saving the Model

```{r}

```



